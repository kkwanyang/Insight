{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy import interp\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import confusion_matrix, classification_report, recall_score, precision_score, precision_recall_curve, roc_curve, auc\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score, KFold, StratifiedKFold\n",
    "from patsy import dmatrices\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "import statsmodels.api as sm\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_adjusted_outcome(model_probabilities,threshold):\n",
    "    y_adjusted=[]\n",
    "    for prob in model_probabilities:\n",
    "        if prob[1] > threshold:\n",
    "            y_adjusted.append(True)\n",
    "        else:\n",
    "            y_adjusted.append(False)\n",
    "    return y_adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset and Reordering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename='ATA_data.csv'\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "df=df.drop('Unnamed: 0',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking interesting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_to_keep=['installed', 'clicked', 'impression', 'app_type', 'weekday', 'hours', 'device', 'country', 'publisher_name', 'app_name']\n",
    "filtered_df=df[cols_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratio=np.mean(df['installed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Downsampling by target downsample rate\n",
    "TotalData=130000\n",
    "Fsamples=int(np.round(TotalData*(1-ratio)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "False_df=filtered_df[filtered_df['installed'] == False]\n",
    "Truth_df=filtered_df[filtered_df['installed'] == True]\n",
    "\n",
    "df2_false=resample(False_df, n_samples=Fsamples, random_state=0, replace = False)\n",
    "df2_truth=resample(Truth_df, n_samples=TotalData-Fsamples, random_state=0, replace = False)\n",
    "# Merge the downsampled False with total True outcomes\n",
    "less_imbalance=pd.concat([df2_false,df2_truth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130000, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "less_imbalance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_com,X_com = dmatrices('installed ~ C(hours) + C(device) + C(weekday) + C(app_type) + C(country) +C(publisher_name)'\n",
    "               ,less_imbalance, return_type='dataframe'\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_com=np.ravel(y_com.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    x_baseline = range(0,110,10)\n",
    "    y_baseline = x_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rstates=[0,1,2,11,4,5,6,7,8,9,10]\n",
    "ymodel=np.empty((11,11))\n",
    "lifts=np.empty((11,11))\n",
    "\n",
    "for r,index in enumerate(rstates):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_com,y_com, test_size=0.2, random_state=rstates[r])\n",
    "\n",
    "    modelLogR2 = LogisticRegression(class_weight='auto',fit_intercept=False);\n",
    "    modelLogR2.fit(X_train, y_train);\n",
    "    probLR2 = modelLogR2.predict_proba(X_test)\n",
    "    pranks = range(0,100,10)\n",
    "    pranks = pranks[::-1]\n",
    "    Test_df = pd.DataFrame(probLR2[:,1], columns=['Prob'])\n",
    "    Test_df['Outcome'] = y_test\n",
    "    num_of_customers = np.empty((10,1))\n",
    "    num_response = np.empty((10,1))\n",
    "    response_rate = np.empty((10,1))\n",
    "    total_pos_outcomes = Test_df['Outcome'].sum()\n",
    "\n",
    "    for i,percent in enumerate(pranks):\n",
    "        rank_percent = np.percentile(probLR2[:,1],percent)\n",
    "        Prob_df = Test_df[Test_df['Prob'] > rank_percent]\n",
    "        num_of_customers[i,:] = Prob_df.shape[0]\n",
    "        num_response[i,:] = Prob_df['Outcome'].sum()\n",
    "        response_rate[i,:] = num_response[i,:]/(total_pos_outcomes)*100\n",
    "\n",
    "\n",
    "    Gain_df = pd.DataFrame(num_of_customers, columns=['No. of Impressions'])\n",
    "    Gain_df['No. of Installs'] = num_response\n",
    "    Gain_df['Response Rate %'] = np.round(response_rate,0)\n",
    "\n",
    "\n",
    "\n",
    "    y_model=[0]+(list(Gain_df['Response Rate %']))\n",
    "\n",
    "    lift = np.round(list(np.array(y_model)/np.array(x_baseline)),1)\n",
    "\n",
    "    lift[0] = 1\n",
    "    ymodel[r,:] = y_model\n",
    "    lifts[r,:] = lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict=modelLogR2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    7  7132]\n",
      " [    3 18858]]\n"
     ]
    }
   ],
   "source": [
    "print confusion_matrix(y_test, y_predict, labels=[True, False]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for i,r in enumerate(rstates):\n",
    "#   plt.plot( x_baseline, ymodel[i,:], '-')\n",
    "plt.plot(x_baseline, y_baseline, 'rs--')  \n",
    "plt.plot(x_baseline,pd.DataFrame(ymodel).mean(), '--', color=(0, 0, 0), label='Mean')\n",
    "plt.xlim([0, 100.5])\n",
    "plt.xlabel('% of Impressions Sampled', fontsize = 18)\n",
    "plt.ylabel('% of Installs Found', fontsize = 18)\n",
    "plt.title('Gains Chart', fontsize = 18)\n",
    "plt.xticks(x_baseline,x_baseline, fontsize = 14)\n",
    "plt.yticks(y_baseline,y_baseline, fontsize = 14)\n",
    "plt.savefig('Gains_Charts.png', dpi=200)\n",
    "plt.legend(['Baseline', 'Mean'], fontsize = 14, loc =0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1080c2e50>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(x_baseline,pd.DataFrame(ymodel).mean(), '--', color=(0.6, 0.6, 0.6), label='Mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.000000\n",
       "1      14.636364\n",
       "2      31.090909\n",
       "3      55.272727\n",
       "4      71.090909\n",
       "5      81.000000\n",
       "6      87.909091\n",
       "7      88.545455\n",
       "8      93.272727\n",
       "9      95.727273\n",
       "10    100.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ymodel).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for i,r in enumerate(rstates):\n",
    "#    plt.plot(x_baseline, lifts[i,:], '-')\n",
    "plt.plot(x_baseline,pd.DataFrame(lifts).mean(), '--', color=(0, 0, 0), label='Mean')\n",
    "plt.plot(x_baseline, np.ones(11), 'rs--')\n",
    "plt.xlim([10, 100.5])\n",
    "plt.ylim([0.5,3.0])\n",
    "plt.xlabel('% of Impressions Sampled', fontsize = 18)\n",
    "plt.ylabel('Lift', fontsize = 18)\n",
    "plt.title('Lift Chart', fontsize = 18)\n",
    "plt.xticks(x_baseline,x_baseline, fontsize = 14)\n",
    "plt.yticks([0.5, 1, 1.5, 2, 2.5, 3],[0.5, 1, 1.5, 2, 2.5, 3], fontsize = 14)\n",
    "plt.legend(['Mean', 'baseline'], fontsize = 14)\n",
    "plt.show()\n",
    "plt.savefig('Lift_Charts.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(lift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Prob_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.min(Prob_df['Prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rm=[LogisticRegression(fit_intercept=False), RandomForestClassifier(), GradientBoostingClassifier()]\n",
    "cvs=5\n",
    "model_aucs=np.empty((len(rm),cvs))\n",
    "model_recalls=np.empty((len(rm),cvs))\n",
    "model_precision=np.empty((len(rm),cvs))\n",
    "\n",
    "for i,models in enumerate(rm):\n",
    "    \n",
    "    model_recalls[i,:] = cross_val_score(models, X_com, y_com, scoring = 'recall', cv = cvs)\n",
    "    model_precision[i,:] = cross_val_score(models, X_com, y_com, scoring = 'precision', cv = cvs)\n",
    "    model_aucs[i,:] = cross_val_score(models, X_com, y_com, scoring = 'roc_auc', cv = cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_matrices = np.empty((6,len(rm)))\n",
    "summary_matrices[0, :] = np.mean(model_recalls, axis=1)\n",
    "summary_matrices[1, :] = np.std(model_recalls, axis = 1)\n",
    "summary_matrices[2, :] = np.mean(model_precision, axis=1)\n",
    "summary_matrices[3, :] = np.std(model_precision, axis = 1)\n",
    "summary_matrices[4, :] = np.mean(model_aucs, axis=1)\n",
    "summary_matrices[5, :] = np.std(model_aucs, axis = 1)\n",
    "print summary_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_df=pd.DataFrame(summary_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='auto', criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRandomForest= RandomForestClassifier(class_weight='auto')\n",
    "modelRandomForest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importances = modelRandomForest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in modelRandomForest.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(287,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Feature importances\", fontsize = 18)\n",
    "plt.bar(range(len( importances[indices[0:10]])), importances[indices[0:10]],\n",
    "       color=\"r\", align=\"center\")\n",
    "plt.xticks(range(len( importances[indices[0:10]])), index_importance, rotation = 60, fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.xlim([-1, 10.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_importance = [u'Publisher A', u'Phone',\n",
    "       u'USA', u'Sunday', u'Friday',\n",
    "       u'Publisher B', u'Saturday',\n",
    "       u'1 p.m.', u'Publisher C',\n",
    "       u'Publisher D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C(hours)[T.13]'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 19,  2,  8, 22, 12, 21, 17, 16, 10,  1, 23,  5,  4, 20, 13, 18,\n",
       "       14,  0,  3,  7,  9, 11,  6])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "less_imbalance['hours'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'C(publisher_name)[T.Tapps]', u'C(device)[T.Phone]',\n",
       "       u'C(country)[T.USA]', u'C(weekday)[T.7]', u'C(weekday)[T.5]',\n",
       "       u'C(publisher_name)[T.Ensolight Interactive]', u'C(weekday)[T.6]',\n",
       "       u'C(hours)[T.13]', u'C(publisher_name)[T.Scopely, Inc.]',\n",
       "       u'C(publisher_name)[T.SEGA]'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns[indices[0:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random Forest Predictions\n",
    "predictedRF = modelRandomForest.predict(X_test)\n",
    "probsRF = modelRandomForest.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probsRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look at precision/recall and confusion matrix\n",
    "\n",
    "print confusion_matrix(y_test,predictedRF, labels=[True, False]).transpose()\n",
    "print classification_report(y_test,predictedRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look at precision/recall and confusion matrix\n",
    "\n",
    "print confusion_matrix(y_train,predictedRF, labels=[True, False]).transpose()\n",
    "print classification_report(y_train,predictedRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs.sum()/y_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_class_outcome(model_probabilities,select_class):\n",
    "    prob_class=[]\n",
    "    for prob in model_probabilities:\n",
    "            prob_class.append(prob[select_class])\n",
    "    return prob_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probRF1=prob_class_outcome(probsRF,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(probRF1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.where(probRF1 == 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probRF1.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
